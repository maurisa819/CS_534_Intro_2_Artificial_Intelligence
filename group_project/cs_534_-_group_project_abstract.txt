CS 534 Group Project Abstract

Spring 2025

TITLE: SmartLearn: AI-Driven Knowledge Assessment and Personalized Video Education. 
ABSTRACT: SmartLearn is an AI-powered adaptive learning assistant designed to help students navigate the overwhelming volume of online educational content. By using GPT-based quiz generation, knowledge assessment, and a hybrid video recommender system, the platform classifies learners into personalized learning levels and delivers YouTube resources tailored to their needs. The system leverages machine learning models for performance classification and personalized quiz suggestions, aiming to enhance both engagement and retention. Preliminary results suggest strong accuracy in classification and relevance of recommended content, with future plans including A/B testing and integration into broader educational systems.

TITLE: Predicting Dropout Incidence with Machine Learning. 
ABSTRACT: An achievement gap refers to the persistent disparities in academic performance due to many barriers such as limited access to funding or inadequate academic support. This tends to result in specific groups of students consistently underperforming in comparison to others. Understanding student success based on demographic and socioeconomic factors can help for early action and building out strategies to mitigate external factors resulting in student drop out rates. This study focuses on predicting student dropout incidence utilizing three state of the art (SOTA methods) including: a multilayer perceptron neural network, random forest, and K-Nearest Neighbors. The data utilized was taken from the UCI ML Repository and underwent extensive pre-processing, where afterwards each of the three SOTA methods was trained via grid search, with the highest performing model being used for testing and comparison. It was found that the Neural Network was highest performing in terms of precision and recall, however, both KNN and Random Forest had very close results.

TITLE: AI/ML Techniques to Improve Sleep Quality Using Wearable Devices. 
ABSTRACT: Sleep is undeniably important in just about all aspects of human life. An individual’s physical and mental health rely significantly on receiving enough sleep daily. The CDC recommends at least 7 hours of sleep to adults, but a significant portion of adults do not meet this benchmark, creating problems in their day-to-day lives. Nowadays, technology and wearable devices play an important role in people’s lives, allowing them to track daily movements, exercise metrics, and their sleep quality. In this methodology, we develop three independent models inspired by existing models with the purpose of predicting sleep quality through data gathered by sleep devices. We implement a deep learning model, a machine learning simple neural network, and a health large language model to achieve this goal. The models differ in complexity and performance metrics vary between them, but each model helps form a better understanding of how different factors relate to sleep quality. Current and future work in machine learning models to predict sleep through wearable device data could be used to improve understanding of how several aspects of health and activity affect sleep, and accurate predictions can create endless benefits in individual health and overall well-being.

TITLE: Apollo AI: AI-Driven Lunar Landing. 
ABSTRACT: The Apollo AI project presents a comprehensive investigation into AI-driven autonomous landing systems for lunar exploration modules, addressing the complex challenges posed by the dynamic and uncertain lunar environment. Leveraging the LunarLander-v3 simulation from Gymnasium, this study evaluates and compares three state-of-the-art (SOTA) methods: Monte Carlo Tree Search (MCTS), Deep Reinforcement Learning (DRL), and Neural Network-Based Model Predictive Control (NN-MPC). MCTS explores randomized landing scenarios to identify robust strategies, DRL trains an agent through trial-and-error to optimize throttle and orientation adjustments, and NN-MPC combines neural networks with control theory for real-time trajectory optimization. Key milestones include implementing these methods using libraries such as PyTorch, Gymnasium, and NumPy, and evaluating their performance based on landing accuracy, fuel efficiency, and stability. Preliminary results highlight the adaptability of DRL, which successfully solved the environment by achieving an average score of 200+ after 691 episodes, demonstrating its ability to learn precise control policies despite early exploration challenges. In contrast, MCTS struggled with computational inefficiency due to the environment's stochastic initialization and the difficulty of replicating simulations accurately, while NN-MPC faced limitations in dynamics modeling, as its learned neural network failed to predict the environment's nonlinear physics reliably. These findings underscore the trade-offs between model-free (DRL) and model-based (MCTS, NN-MPC) approaches in complex, sparse-reward tasks. The project aligns with real-world space exploration goals, such as NASA’s Artemis program, by advancing autonomous landing technologies critical for future lunar and Martian missions. Future work will focus on hybrid methods, improved dynamics modeling, and real-world robustness enhancements to bridge the gap between simulation and deployment.

Fall 2024

TITLE: Detecting Media Bias with Artificial Intelligence. 
ABSTRACT: Media is a primary source of information for many people, but it often contains bias that can shape how viewers interpret information. This project addresses the problem of media bias by leveraging artificial intelligence to detect bias at the sentence level. The team began by researching datasets previously used for media bias detection including BABE, MBIB, and BASIL, and selected the BABE dataset, which includes expert-level annotations, to train various models. State-of-the-art models, including BERT, RoBERTa, BiPolar, T5, and XLNet, were employed for bias detection, with an additional layer of media bias detection data, to improve the performance of each model. Each model's effectiveness was evaluated using metrics such as accuracy, precision, and F1 score. Based on these findings, the team developed an ensemble model combining BERT, RoBERTa, and XLNet to optimize sentence-level bias detection. The Bipol and T5 models were determined less effective and were not included in the ensemble due to their weaknesses. This ensemble model demonstrated improved performance compared to each individual model, providing an effective tool for detecting media bias. The results highlight the use of artificial intelligence models for effectively detecting media bias, offering a step forward in promoting more impartial information perceived in media.

TITLE: Grocery Identification & Assistant. 
ABSTRACT: This project develops a grocery identification and tracking system powered by a custom-trained Ultralytics YOLOv11 model and a modified ByteTrack algorithm that can keep track of items within a shopping cart and manage a shopping list from a user. The system integrates object detection, multi-object tracking, dynamic list management, and a front-end application to streamline the shopping experience for a user. The system can be used in various environments because to set up the system, a user can define a shopping cart polygon for any webcam. The system detects groceries in real time, checks off items from the list when they enter the cart and removes them if they are no longer detected. Our project creates an efficient and streamlined shopping experience for users. Key milestones this research completed include successful YOLO model training, multi-item detection and tracking, and implementation of a user-friendly front-end interface for the list management system. While the method works efficiently, future user applications will require adding more classes of objects to identify all groceries within a store. The method developed in this research could be leveraged for autonomous or enhanced shopping carts to improve operational efficiency for large supermarket chains.

TITLE: Sentiment Analysis of Social Media Tweets. 
ABSTRACT: Due the increase in popularity and usage of social media in the last decade, there is a significant amount of information that can be collected and mined. In this project, we specifically focused on Tweets, which range from simple phrases to short paragraphs of text. Analyzing this data to gain insights is referred to as natural language processing, or NLP. However, NLP is quite a broad field with many different methodologies, so more specifically, we focused on Sentiment analysis, which takes a text input, and classifies what the sentiment of the message. Using 30,000 tweets, we trained and tested 5 unique state-of-the-art (SOTA) NLP models for sentiment analysis, classifying each tweet as “positive”, “negative”, or “neutral.” After experimenting, we found that GRUBERT had the highest performance, scoring an accuracy, precision, and recall of 0.79, 0.79, and 0.79. With these models trained and tuned, we implemented them on new tweets collected prior to the election to train and gauge public sentiment on social media.

TITLE: AI Personal Computer Builder and Optimizer. 
ABSTRACT: The increasing demand for personal computers in recent years and the limited knowledge many consumers have about building them highlight the need for a tool that simplifies the component selection process through a component recommending system. This tool would allow users to compare pricing, ratings, and various performance metrics when assembling a PC. Current solutions are primarily web-based and often require users to manually analyze data and know component comparison metrics, which can be complex and time-consuming. This project addresses these challenges by leveraging AI algorithms to analyze extensive datasets and provide optimized component recommendations. The approach involves five advanced algorithms: four for data filtering and analysis using distinct optimization techniques, and a fifth for synthesizing and optimizing the results from the previous four. These algorithms evaluate both quantitative and qualitative data, considering factors such as budget constraints and user experience levels throughout the process. The system is designed to balance cost, performance, and user preferences while simplifying decision-making for PC builders of all skill levels. By combining state-of-the-art methods with a user-centric focus, this tool aims to streamline the PC-building process and make it more accessible to a broader audience.

TITLE: AI-based indoor navigation and SLAM technology for quadcopter UAVs. 
ABSTRACT: This project focuses on indoor navigation and monitoring for quadcopter UAVs by integrating state-of-the-art (SOTA) AI methods. This project aims to enhance UAV’s autonomous navigation in complex indoor environments like warehouses, office buildings, and emergency scenarios by addressing the limitations of traditional monitoring systems, such as blind spots and reliance on significant manpower. Complex challenges such as navigation in cluttered indoor spaces and real-time obstacle avoidance are addressed using the YOLOv11 object detection model because of its balance of speed and accuracy in detecting and classifying objects. Our approach incorporates data preprocessing, model training on Kaggle’s indoor object detection dataset, and the use of a rule based control system to adjust UAV flight paths dynamically. The project workflow includes data collection, image preprocessing, model training, and real-time evaluation, ensuring UAVs can operate autonomously with precision. Experiment results indicate improved object detection accuracy, reduced loss metrics, and efficient navigation within a simulated environment. The model successfully identifies features such as tables, chairs, and obstacles while maintaining a stable flight. Key milestones include developing an image recognition model, optimizing the model performance, and simulating indoor environments. Future work will compare YOLOv11 with other SOTA methods and refine navigation strategies, further contributing to UAV-based indoor navigation solutions.

TITLE: Artificial Intelligence in Traffic Monitoring in Large Cities. 
ABSTRACT: Traffic congestion in large cities results in economic losses, increased pollution, and reduced quality of life. In 2019, traffic delays cost the U.S. economy $87 billion, with commuters losing an average of 54 hours in traffic (Inrix, 2019). This research focuses on the use of Artificial Intelligence (AI) to reduce these challenges. Five state-of-the-art methods—fuzzy logic, recurrent neural networks (RNN), and the YOLO (You Only Look Once) system—were evaluated for real-time vehicle detection and traffic analysis. Among these, YOLO emerged as particularly effective due to its accuracy in detecting multiple objects and generating actionable insights for traffic management. Thus by leveraging the unique strengths of these methodologies, the project proposes a comprehensive AI-driven traffic management system capable of optimizing traffic light timings, improving traffic flow and reducing congestion. However, challenges related to scalability, computational efficiency and neural network training remain. The project proposes a traffic management system that integrates AI to improve urban mobility.

TITLE: Music Classifier. 
ABSTRACT: This project investigates the application of artificial intelligence (AI) for classifying music genres using the GTZAN dataset, a widely used benchmark in music classification. Five state-of-the-art methods were explored: Pre trained Audio Neural Networks (PANN), Paired Inverse Pyramid MLP Networks (PIPMN), Random Forest, Convolutional Neural Networks (CNNs), and Convolutional Recurrent Neural Networks (CRNNs). Each approach was implemented and evaluated on the dataset's 30-second wav audio features, focusing on classification accuracy, training time, and memory efficiency. Random Forest achieved an overall accuracy of 56.5%, while CRNNs reached 50%, with distinct strengths and weaknesses across genres. Challenges included integrating the dataset into PANN and PIPMN frameworks, addressing compatibility issues, extracting features from the GTZAN audio files, and optimizing preprocessing workflows. The study found that while Random Forest and CRNNs showed promise, their performance varied significantly by genre, with specific difficulties in accurately classifying reggae and rock music. Preliminary results indicate that additional optimization and standardization across all methods are necessary for robust comparison and improved results. This work provides meaningful insights into the potential of machine learning for music analysis, setting the stage for further exploration of automated genre classification systems and their valuable applications in music recommendation and AI based composition tools.

TITLE: LayerFusion: A workflow for advanced image production using GenAI. 
ABSTRACT: Layered image creation is fundamental to professional digital media production, yet current AI image generation tools produce only flat, single-layer outputs that cannot be easily integrated into professional workflows. We present LayerFusion, an ensemble pipeline that combines multiple state-of-the-art image segmentation methods to automatically convert AI-generated images into layered compositions. Our approach leverages five leading segmentation techniques including CLIPSeg, ODISE, YOLO, HIPIE and Detectron2, orchestrated through a modular pipeline that handles both RGB and depth-based segmentation. The pipeline accepts any AI-generated image along with its creation prompt and outputs separated layers containing discrete objects mentioned in the prompt. We evaluate our methodology using both objective metrics (Structural Similarity Index, Edge Match Ratio) and practical benchmarks (task completion). The system provides artists and content creators with a crucial bridge between AI generation capabilities and professional digital media workflows.

Summer 2024

TITLE: Finance Bench: A New Benchmark for Financial Question Answering using LLMs. 
ABSTRACT: Our project evaluates the effectiveness of Large Language Models (LLMs) for financial questionanswering using Finance Bench, a benchmark designed for this purpose. Traditional financial information retrieval methods are inefficient with the increasing volume of data. LLMs, with their capabilities in Natural Language Processing (NLP), present a promising solution. However, their ability to handle the complexities of financial data remains underexplored. Our approach involves using several state-of-the-art (SOTA) methods, including finetuning pre-trained language models, retrieval augmented generation, financial entity recognition, and transformerbased architectures with financial attention. We will configure these models on the Finance Bench dataset and establish an evaluation framework combining automatic and human metrics to assess their performance. The project aims to identify the most effective method, balancing accuracy, factual grounding, and explainability. Our initial results indicate promising avenues for LLMs in financial question answering, with ongoing work to refine and compare the selected methods.

TITLE: Finance and Stock Assistance. 
ABSTRACT: Team Finance Fellas has been working on developing an AI agent that can help investors predict the stock market to enhance their investment portfolio. The project has many different ways to attempt implementing this AI agent which includes Artificial Neural Networks (ANN), Machine Learning (ML), Temporal Fusion Transforms (TFT), and Large Language Models (LLM). This methodology variance provides a better insight into the different approaches to solving the problem that yielded different results. Diversified implementation techniqueshelped the development and enhancement of the project that later compares these various approaches to pick the best. Although the results are hard to perfect with the available data and computation power, the group was able to assess the quality of each of the methods used.

TITLE: Predicting River Erosion and Path Changes with Satellite Images. 
ABSTRACT: Predicting river erosion and path changes is crucial for managing ecological balance, agriculture, and human settlements. This report leverages satellite imagery and state-of-the-art AI methodologies to forecast these changes, aiming to mitigate the devastating effects of riverbank erosion, such as agricultural land loss, infrastructure destruction, water pollution, and community displacement. Current methods, including Convolutional Neural Networks (CNNs), Long Short-Term Memory networks (LSTMs), Vision Transformers (VITs), and Superpixel Segmentation, each offer unique advantages and challenges. This project combines VITs and LSTMs and CNNs to predict river erosion using Google Earth Timelapse Engine videos from 1984 to 2022. Preprocessing involves extracting regions of interest and chronological sorting of images. Superpixel segmentation simplifies the classification problem, while LSTMs handle the temporal aspects of river morphology. The proposed model's performance will be evaluated using accuracy, precision, recall, F1 score, and Matthews correlation coefficient (MCC). This approach aims to provide valuable insights for environmental management and disaster prevention, highlighting the potential of AI in predicting and mitigating the impacts of natural disasters. The proposed model has offered several key results: the ability to predict slight changes in aerial river images and semantic segmentation, classifying rivers from all other features within an image. However, the diversity of our image sets proved to be unable to generalize to all regions of the world, due to drastically different climates and erosion rates of rivers.

TITLE: Hallucination Detection in Large Language Models (LLMs). 
ABSTRACT: The integration of Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) into various sectors has been transformative, yet it raises significant ethical concerns. Among these, the propensity of LLMs to generate ‘hallucinated’ content—outputs that are factually incorrect or entirely fabricated—is particularly troubling. Such inaccuracies can have dire consequences, especially in critical fields like healthcare and emergency response. Our research addresses this issue by implementing and evaluating state-of-the-art (SOTA) methods for detecting hallucinations in LLMs. Our approach involves implementing sophisticated natural language processing techniques and AI model training to identify and flag potentially inaccurate outputs. We utilize GPT3.5turbo as a benchmark for our study, employing a framework of multiple domain-specific hallucination detection models. A transformer classifier, achieving 90% accuracy, directs prompts to the appropriate detection model. Key results include the development of a robust hallucination detection system and the finding that GPT3.5-turbo produces hallucinations in approximately 25% of prompts. This research contributes significantly to the safe and responsible application of AI technologies, paving the way for their beneficial integration into society while mitigating risks associated with misinformation and inaccuracies in AI-generated content.

TITLE: Wireless Charging Alignment for EVs using Computer Vision. 
ABSTRACT: Electric vehicles are becoming increasingly popular, and companies such as Witricity are seeking to make charging more convenient and efficient by implementing wireless charging in vehicles. Our project seeks to demonstrate the potential for autonomous parking of vehicles using computer vision, such that EVs can be reliably aligned with a wireless charging pad. Our solution implements the state of the art CV methods of YOLOv8, Intrinsic/Extrinsic camera calibration, and Principle Component Analysis. A subscale model of a car and charging pad was created. A differential drive robot was used to represent the car, and an overhead camera was mounted to use for computer vision. A custom YOLOv8 model was trained on a dataset of 300 images of aerial views of cars. Camera calibration was performed using OpenCV, and a measured grid of points on the test setup. Principle Component Analysis was used to determine the orientation of the vehicle. A working demonstration was created where the vehicle could be detected by YOLOv8, real-world position and orientation was determined, and commands were sent to drive the vehicle to a specified location.

TITLE: Produce Classifier. 
ABSTRACT: Automated produce classification is an emerging need in the grocery and farming industry. Grocers and farmers waste both time and natural resources needlessly labeling produce that normally can be identified by the human eye. In addition, with increased legislation from France and New Zealand, plastic food stickers are being phased out due to their inability to be composted. The method presented in this paper aims to solve this issue using machine learning and artificial intelligence to quickly and accurately identify produce when customers are checking out from a grocery store. We’ve taken a modular approach that will allow for the easy addition of more classes of produce down the line without a full retraining. The model employs YOLOv8 for object detection to crop the produce from a scene. The cropped images are then passed to a Level 1 classifier which classifies the produce class. After the class is identified, the cropped images are passed to their respective Level 2 classifiers to determine the variety of the produce. The confidences of the Level 2 classifier are combined to result in a single variety of produce with a single confidence for the overall image. This model is compared against other State-Of-The-Art (SOTA) methods for classifying produce. The model was trained and tested on three varieties of oranges (clementine, navel, mandarin), four varieties of apples (honeycrisp, red delicious, granny smith, fuji), and two varieties of tomatoes (roma, cherry red). The model was able to classify the nine varieties of produce with an overall accuracy of 97%, eight of which had an accuracy greater than 90%.

TITLE: Using AI to Diagnose Lung Diseases. 
ABSTRACT: Misdiagnosis of lung diseases, where patients have a high risk of permanent damage or death, is heavily reliant on expertise, speed of diagnosis, and is high risk of succumbing to human error. The possibility of improved diagnostic methods is an area in which high-speed, accurate predictions from automated image analysis technology can play a pivotal role. Image segmentation technologies are being tested and utilized in the medical field to improve the rate of misdiagnosis, so we compare some of the highest-performing models against each other to understand what methodologies are most effective. We test four state-of-the-art methodologies for image analysis through image segmentation, using convolutional neural networks and swin transformers. The models are trained on X-ray images of lung diseases from the ChestX-ray8 dataset. We use the models KiU-Net, nnU-Net, Res-Net, and Swin UNETR and compare the results of each trained model on a test set against each other to determine their effectiveness. We obtain statistics and example predictions from the trained models and use those for comparison.

TITLE: AI Tutoring Bot - N.E.R.D. (Knowledgeable Educational Resource Device). 
ABSTRACT: The cost of private tutors is prohibitively expensive for most American high school students, but that doesn’t change the need for them. Half of all U.S. students are below grade level in at least one subject and most classrooms have a 25:1 ratio of students to staff, making it impossible for students to get individual support. This project seeks to remedy this by providing free, high quality tutoring using AI instructors. We chose AP U.S. History as a proof of concept. Based on a paper by Rice University, we will use the CLASS training structure for our LLM (Llama3) to make it produce dynamic and guiding responses, instead of a ChatGPT style answer that doesn't help students learn. This framework interacts with RAG, which uses a large dataset of AP U.S. History study guides and questions to pull accurate information and then formulate it in a user-friendly manner with the CLASS LLM. After training the model on CLASS using the dataset from Rice, analysis by team members concluded that we generated significantly more useful responses than ChatGPT. Model accuracy did not noticeably improve when connected to RAG, likely because the LLM was already well versed in U.S. History, and the limited size of our RAG. Due to limitations of computing power, we were unable to connect the LLM/RAG to ChatGPT to evaluate in a more rigorous manner.

Spring 2024

TITLE: Company Sentiment Analysis and Performance Modeling. 
ABSTRACT: Social media has become ubiquitous over the past twenty years, with over 5.04 billion users as of January 2024. Because social media posts reach so many people, the content of the posts has the potential to cause real-world ramifications. In this project, we investigate how social media sentiment can have immediate effects on a company's stock price, with a focus on Reddit posts about Amazon in 2022. We aim to create a way to alert companies about social media sentiment and the potential business impact ahead of time. First, we explore how we can classify the sentiment of posts as positive or negative using state-of-the-art methods, namely RoBERTa, Electra, XLNet, and ULMFiT, as well as classify the emotion of posts using Distil-RoBERTa. We then include the sentiments in ARIMA, ARIMA-GARCH, and LSTM models to forecast Amazon’s daily stock price. Despite including sentiment scores, the models do not produce accurate stock price forecasts. Ultimately, social media sentiment is only one factor that influences business performance. It is necessary to include features besides social media sentiment for accurate performance modeling.

TITLE: Detecting Emotions in Literature to Accommodate Youths. 
ABSTRACT: The goal of this project was to evaluate the use of various SOTA methodologies to perform sentimental analysis on text from literature. The reason for focusing on this task was finding research indicating that children statistically have a tougher time being able to recognize the emotions of characters in literature when they only have text and no pictures. We saw this as a barrier in being able to engage with literature and that a tool that could help a child understand emotions of text to benefit their understanding of the text. Our approach for this was to evaluate the SOTA methods of LSTM, CNN, BERT, and RoBERTa on multiple different metrics to determine which was the best and for classifying emotional sentiment of text from literature. The results of this showed that BERT and RoBERTa were the best methods for emotional labeling. We trained the models using a dataset of sentences from public domain literature labeled with 38 different emotions. RoBERTa was able to achieve an accuracy of 75%, a precision of 75%, an F1 Score of 75%, Recall of 75%, and an MCC-Score of 0.7432.

TITLE: Evaluating Different SOTA Approaches to Most Efficiently Diagnose Colon Cancer. 
ABSTRACT: Colorectal cancer is rising among young adults, necessitating early screening due to its varied symptoms and potential complications. It motivates the development of automated diagnostic tools. In this research, 4 SOTA deep learning methods are implemented to deal with colorectal diagnosis, which includes Segmented Image Processing via CNN, Deep Feature Extraction and Ensemble Learning, and Annotated Image Processing via YOLOv5. As the database utilized in this work is 10k colon cell slice images including health and cancer, all of these training models are under supervision during work for better availability. Employing these four distinct state-of-the-art methods, it effectively classifies colorectal cancer using artificial intelligence, and identifies the optimal approach for analysis. As evidenced by the comparative metrics table, indicating that the Image Reconstruction & Modified DenseNet model stands out as the most suitable method for it.

TITLE: Dynamic Instructions with cOmposable Scripts (DINOS). 
ABSTRACT: The Dynamic Instructions with cOmposable Scripts (DINOS) framework addresses the limitations of Large Language Models (LLMs) in following precise instructions by generating a dynamic, composable, and verifiable benchmark for instruction-following tasks. The real-time generation of diverse and composable instruction sets allows for the creation of a large corpus of evaluation data while minimizing the risk of benchmark contamination. DINOS introduces instruction constraints and problem classes that test an LLM’s ability to adhere to specific criteria and solve various problems. An iterative training pipeline utilizes the DINOS benchmark to finetune a base model (Llama-3-8B) through self-play and preference-tuning techniques, aiming to improve its general instruction-following capabilities. The effectiveness of this approach is evaluated by comparing the performance of the fine-tuned model against other similarly-sized state-of-the-art models on established benchmarks like MMLU and IFEval, as well as the DINOS benchmark itself. Preliminary experimental results highlight the importance of tiered instructions, fine-grained evaluation, and the incorporation of model perplexity. By providing a dynamic and verifiable benchmark, DINOS enables the development of LLMs with strong general instruction-following abilities, paving the way for their reliable application in sensitive domains such as law and healthcare.

TITLE: Using Artificial Intelligence to Speedrun/Test Video Games.
ABSTRACT: This project aims to address the challenge of optimizing video game testing and speedrunning using state-of-the-art Artificial Intelligence (AI) technologies. Given the projected growth of the AI-enabled testing market, our research employs advanced AI methodologies, such as Reinforcement Learning, Deep Learning through Convolutional Neural Networks, and Preference Guided Deep Q Networks (PGDQN), to enhance testing efficiency and reduce the repetitive workload traditionally required of human testers. We conducted experiments within popular video game environments, including Donkey Kong and PONG, where AI agents autonomously learned and optimized gameplay and bug detection. Our results show a clear learning and improvement in agent performance, and the potential for increased bug detection efficiency compared to traditional methods. These findings demonstrate the effectiveness of AI in reducing development times and costs while increasing the thoroughness of game testing. The project has not only advanced the application of AI in game testing but also established a foundation for further exploration into AI's potential to improve efficiency in other testing domains.

TITLE: Detection of Blood Cell Abnormalities Using Blood Cell Image Classification. 
ABSTRACT: This paper explores the significance of imaging technologies in analyzing blood cells for medical diagnosis and treatment monitoring. Blood Cell Abnormalities (BCA) can indicate various illnesses, emphasizing the importance of quick and accurate analysis. Our study focuses on quantitative and qualitative BCA detection, particularly targeting diseases like Sickle Cell Anemia (SCA) and leukemia. With the projected increase in SCA cases and the promising survival rates of leukemia, early diagnosis becomes paramount. Our analysis delves into the current State-of-The-Art (SOTA) methods, primarily leveraging Convolutional Neural Networks (CNNs) for image classification. Notable architectures such as ResNet-50 and EffNet exhibit high accuracy rates in detecting abnormalities. Our evaluation process, centered on the Blood Cell Count Detection (BCCD) dataset, emphasizes metrics like accuracy, precision, recall, and F1-score to assess model performance. Experimental setups encompass rigorous pre-processing and data-handling techniques to ensure uniformity and model generalization. This paper also considers computational efficiency and scalability for practical clinical deployment. Recommendations for future research directions and clinical implementation are provided, emphasizing the potential of CNNs in improving diagnostic accuracy and patient outcomes. The comprehensive overview of SOTA models, workflow, and lessons learned offers valuable insights into the advancements and challenges in Blood Cell Image Classification (BCIC) for medical diagnosis.

TITLE: Assessment of State-of-the-Art Deep Neural Networks for the Detection of COVID-19 via Chest X-Rays. 
ABSTRACT: At the end of 2019, Wuhan, China, emerged as the ground zero for the outbreak of COVID-19, a disease caused by the SARS-CoV-2 virus, leading to a worldwide health emergency declared by the World Health Organization. With the virus affecting 216 countries and causing extensive morbidity and mortality, accurately differentiating COVID-19 from similar respiratory diseases became imperative. Leveraging artificial intelligence, specifically state-of-the-art convolutional neural networks, offers a promising solution for enhancing the accuracy and speed of diagnosing COVID-19 through chest X-rays. Given the varied state-of-the-art convolutional neural networks (CNNs) explored for COVID-19 detection in chest X-rays, this paper synthesizes these approaches to present a comprehensive analysis. This project delves into the effectiveness, adaptability, and efficiency of pretrained state-of-the-art models like ResNet-50, VGG-19, and InceptionV3. Furthermore, fine-tuned state-of-the-art models, such as COVID-ResNet, DarkCovidNet, and DenseNet169 and XGBoost, are evaluated to determine if fine-tuned models provide significant benefits over renown, pretrained models, assessing their diagnostic accuracy and operational benefits. Through a rigorous evaluation framework involving accuracy, sensitivity, specificity, and computational efficiency, this project aims to identify the most promising CNN architectures for real-world application, offering a path forward in enhancing rapid and reliable COVID-19 screening methods. Based on the results of the testing accomplished, it was determined that the DenseNet169 and XGBoost model developed by Nasiri & Hasani provides the best results, based on MCC score, to determine COVID-19 in chest x-rays.

TITLE: PL8M8 (PlateMate): an AI Recipe Scheduling System. 
ABSTRACT: This project "PlateMate" aimed to develop an AI-assisted recipe scheduling system that facilitates the creation of daily meal plans related to users’ preferences, allergies, and nutritional needs. This system addresses the common issue of inadequate dietary planning amidst busy lifestyles, a lack of cooking skills, and the rising costs of healthy foods. The project leverages state-of-the-art methods including custom algorithms, solutions to the multidimensional knapsack problem, Semi-Custom Large Language Models (LLMs) like ChatGPT, and neural network approaches to generate personalized meal plans. These methods utilize extensive datasets on ingredient combinations and user preferences, applying complex computational techniques to optimize meal plans for nutrition and cost-effectiveness. The goal is to promote healthier eating habits by making personalized nutrition accessible and convenient, especially for those with limited time or expertise.

TITLE: AI-based Pleural Effusion Detection in Chest X-rays. 
ABSTRACT: In the medical field, identifying diseases is extremely important in early diagnosis. We sought to examine state of the art methods for medical image detection and apply those to pleural effusion. Pleural effusion is the abnormal flooding of fluid in the space around the lungs. We used a subset of the MIMIC-CXR-JPG dataset and created a train-validation-test split of 60%-20%-20% respectively. The methods we examined were ResNet, GoogLeNet, U-Net, and DenseNet. Each model had different structures that we implemented to fit our dataset. After implementing the architectures of each model, we trained and validated each model before making predictions on the test dataset. The predictions were used to calculate the accuracy, recall, F1-score, and Matthew’s correlation coefficient (MCC). We found that the best performing model was ResNet with accuracy, recall, F1-score, and MCC of 0.81, 0.85, 0.82, and 0.62, respectively. Based on this, we recommend that the ResNet model be further adapted to improve its performance by trying a larger variety of architectures, using hyperparameter tuning, and examining validation loss and accuracy throughout epochs. This highly specified model could then be employed by medical institutions to aid in identifying pleural effusion in chest scans.

Fall 2023

TITLE: Pelios: A Real-Time Facial Emotion Recognition Platform. 
ABSTRACT: The ability to recognize human emotions holds significant importance in shaping the future of emerging artificial intelligence technology. We present “Pelios: A real-time facial emotion recognition platform.” The purpose of Pelios is to be a system capable of efficiently and accurately identifying human emotion which can be integrated into commercial and research projects to enhance their performance. We implemented four state-of-the-art methods which make use of convolutional neural networks to predict emotion based on the FER2013 dataset. Each method was chosen based on its accuracy, explainability, computational resource effectiveness, and inference time. The first method uses a VGG-16 CNN with a transfer learning approach to minimize training time. The second method uses rigorous hyper-parameter tuning, varying optimizers, learning rates, and schedulers, to train an end-to-end VGG-16 CNN. The third method uses a modified CNN to minimize model size while maintaining accuracy. Finally, the forth model focuses on a multi-task approach to learn emotion alongside other indicators such as age, race, or gender. The best performing model was the second model which is a single VGG-16 tuned with stochastic gradient descent with a reduce learning rate on plateau scheduler. This model achieved an accuracy of 71.18% and an F1 Score of 0.7038 on our 7 class dataset. We deployed the trained models in a real-time environment, predicting emotion on live video streams, to showcase the effectiveness of the proposed Pelios system.

TITLE: Assessing the Performance and Accuracy of SOTA Convolutional Neural Networks and Vision Transformer models in Medical Imaging.
ABSTRACT: The field of medical imaging has carried out a vital role in the overarching landscape of healthcare since the 1800s up to the modern day. However, overutilization of imaging practices and procedures has led to an increased amount of data throughput for radiologists conducting such practices, increasing the risk of fatigue and burnout among the imaging personnel which in turn increased the likelihood of the presence of errors when performing the medical analysis. To help alleviate the consequences of the increased magnitude of imaging data, the usage of artificial intelligence was proposed as a viable solution to partially, if not completely, automate the process of parsing medical imaging data and determining the appropriate diagnosis for the patient associated with the data. For this project, we implemented and tested five State Of The Art (SOTA) image recognition models on a dataset consisting of x-ray scans depicting the presence of pneumothorax, evaluated the effectiveness of each of the models, and confirmed the viability of these image recognition models for medical imaging. Our results have shown that the majority of the tested image recognition models were able to effectively analyze and classify the x-ray scans as benign or malignant in terms of the presence of pneumothorax, demonstrating a prospective viability of these models in the field of medical imaging.

TITLE: Development and Evaluation of Artificial Intelligence Applications for Predicting Cardiovascular Disease. 
ABSTRACT: Cardiovascular disease is one of the leading causes of death across all regions of the world, being listed as the leading cause in low-income and middle-income countries as well as one of the top five in developed countries (Ezzati, 2021) (Nabel, 2003). Healthcare accessibility makes these diseases even more lethal in lowincome countries, especially as a result of lower budgets for health screening, prevention, and treatment. Even in regions where healthcare is readily accessible, healthcare professionals can struggle to predict and diagnose all cases with confidence, leaving a sizable gap in proper healthcare for people with cardiovascular diseases all over the globe (Nabel, 2003). Our project proposes a machine-learning approach that aims to cover the majority of problems present in current-day healthcare prediction, diagnosis, and accessibility. Through an ensemble approach of machine learning algorithms, our program would take a consensus vote from XGBoost, Random Forest, Support Vector Machine, and K-Nearest Neighbor models on whether or not a patient has a cardiovascular disease based on a small range of easily taken healthcare metrics.

TITLE: Automated Detecting and Classifying Road Signs. 
ABSTRACT: Our AI project addresses a critical global challenge—road safety—through the application of self-driving technology. With nearly 1.3 million annual fatalities stemming from traffic accidents worldwide, our aim is to harness the potential of state-of-the-art methods (SOTA), including YOLOv8, OpenCV, LeNet-5, and SVM, to enhance Traffic Sign Recognition (TSR). Surprisingly, OpenCV emerged as the leading SOTA method, boasting outstanding Model Accuracy (97.59%), F1 Score (0.9759), and MCC score (0.9570). The unexpected performance of LeNet-5 and SVM prompted insightful reflections, with subsequent video testing validating OpenCV's superiority. Despite initial challenges, our hybrid approach, combining YOLOv8 and OpenCV, demonstrated the most effective results. Key takeaways encompass considerations in dataset management, the nuances of shape detection, and the pivotal role of feature extraction. Looking forward, our project sets the stage for future work involving dataset augmentation and exploration, ensuring a robust analysis that holds broader implications for advancing self-driving technologies and road safety.

TITLE: Machine Learning for Fault Detection in Swarm Robotics. 
ABSTRACT: This paper explores artificial intelligence techniques for fault detection in swarm robotics. Four different states of the art methods are evaluated, Time Generative Adversarial Networks (TimeGAN), Gradient Boosting Decision Trees (GBDT), Naïve Bayes, and Long Short-Term Memory (LSTM). A boid simulation is used to generate data with the complex interactions of a robot swarm. There is a significant focus on the challenges posed by infrequent anomalies and imbalanced datasets. The paper provides implementation details, strengths, and limitations of each method, as well as demonstrations of each model on the boid simulation. Future work is discussed, including the use of image data, more realistic simulations, and user studies to evaluate the models.

TITLE: Predictive Analysis of Heart Disease Using AI Algorithms. 
ABSTRACT: Heart disease is a condition that afflicts a significant portion of the population in the United States. Nearly twenty percent of deaths recorded each year can be linked to heart disease, with the toll weighing heavy on the family members whose loved one succumbed to the disease. In order to combat the problem, advancements in machine learning have been made which attempt to target the root cause of many medical issues. Multiple models have been proposed in the past, each with their own advantages and disadvantages. While all models were created in good faith, it is important to identify the most successful model in order to properly assess patients who are considered at risk. This paper explores heart disease predictive analysis through the use of five different state of the art methods: Naive Bayes, Logistic Regression, Support Vector Machine, Decision Tree, and Random Forest. Each method is tested using a standard set of accuracy metrics to adequately assess which model is the best predictor. In order to test these models against one another, hyperparameter tuning and data preprocessing were included where necessary and ensured the experimentation was fair. The model which saw the most success from these trials, Random Forest, was then applied to a sample web application which is meant to encourage individuals to recognize the condition of their health and what actions they may take to improve it. Although Random Forest far exceeds the other SOTA methods in nearly every accuracy metric category, particular attention was given to the recall as this metric evaluates how many sick individuals were correctly classified as so. This metric holds far greater importance than others as it is important to know as early as possible the risk of heart disease.

TITLE: Exploring AI Methodologies to Predict Health Ailments. 
ABSTRACT: Heart disease has been one of the most common and deadly diseases in the United States to the point that it has become the largest cause of death. As our population continues to age and other preventable diseases become less common, heart disease is likely to take its place, and continue to hurt many. Due to this, it is important to get a step ahead and find better approaches to both diagnosing and treating heart disease. We believe that as preventative and remedial technologies develop it is important to also create new technologies that allow for earlier detection of risk of heart disease. The goal of this project was to develop AI models that could help doctors determine whether someone is at risk of heart disease. To achieve this, we researched and trained a variety of machine learning algorithms with the goal of finding one that could most accurately determine if someone was at risk of heart disease. Our approach to this was to find models that could be effective and then optimize them to work best with our dataset. We evaluated these models off of a variety of metrics to select the one that works best given our problem.

TITLE: Natural Calamity Detection. 
ABSTRACT: As natural disasters continue to escalate in frequency and intensity due to climate change, the need for rapid and precise identification becomes paramount in safeguarding lives and infrastructure. Our project focuses on leveraging technological advancements, including advanced sensor networks, satellite imagery, and artificial intelligence, to enhance the efficiency of disaster detection. The overarching purpose of our endeavor is to explore and implement state-of-the-art (SOTA) image classification and object detection methods. By combining these advanced techniques, we aim to develop a robust system capable of swiftly identifying anomalies indicative of various disasters, such as wildfires, earthquakes, floods, and storms. The integration of remote sensing technologies, particularly satellite imagery and aerial monitoring, enables real-time surveillance of extensive geographical areas, empowering our system to detect and respond to potential threats promptly. In our pursuit of milestones, we have initiated comprehensive research into the most effective SOTA methods, established a diverse dataset for training and validation, and begun the development of a prototype system. Our project represents a crucial step forward in leveraging AI to bolster disaster detection capabilities, contributing to the resilience of communities in the face of evolving environmental challenges.

TITLE: Supervising the Growth of AI Cardiac Diagnosis. 
ABSTRACT: In the field of artificial intelligence, the growth and application of technology to cardiac diagnosis hold significant promise for early detection and intervention in cardiovascular diseases. This project endeavors to leverage state-of-the-art machine learning models, including XGBoost, Random Forest, K-Nearest Neighbor, and Logistic Regression, to predict the presence of heart disease. The motivation stems from the critical importance of timely cardiac diagnosis, given the severe consequences of neglecting cardiovascular health. The project team aims to train individual models and combine them into two heterogeneous models, namely Roman Consul and Weighted Ensemble, employing a diverse dataset from the Cleveland Heart dataset. The report outlines a systematic approach involving exploratory data analysis, normalization, model training, and k-fold cross-validation for performance evaluation. However, challenges arose from the initial dataset's unreliability, prompting a transition to the more trustworthy Cleveland Heart dataset. The performance of each state-of-the-art model is assessed using key metrics such as accuracy, precision, recall, F1-score, and the area under the Receiver Operating Characteristic (ROC AUC) curve. To enhance model accuracy, a meticulous hyperparameter tuning process is implemented for each model, with detailed code snippets provided for transparency. The project introduces two ensemble models, Roman Consul and Weighted Ensemble, to harness the strengths of individual models and optimize predictive accuracy. Preliminary experimental results indicate XGBoost as the best-performing model, followed closely by Random Forest and Logistic Regression. Lessons learned emphasize the importance of thorough dataset scrutiny and the accessibility of implementing predictive models using Python and libraries such as scikit-learn. The conclusion highlights achievements, future work prospects, and the development of a web application to demonstrate the trained models' predictive capabilities. This project lays the foundation for further refinements, medical consultations, and expanded applications in cardiac health risk assessment, showcasing the potential of artificial intelligence in transforming cardiovascular diagnosis and treatment.

TITLE: Credit Card Fraud Detection Using Machine Learning. 
ABSTRACT: As digital transactions become increasingly prevalent, the risk of credit card fraud has grown substantially, necessitating the development of robust and effective fraud detection systems. This paper presents a comprehensive study that evaluates and compares the performance of four prominent machine learning methods, Logistic Regression, K-Nearest Neighbors (KNN), Naive Bayes, and Support Vector Machine (SVM), in the context of credit card fraud classification. The dataset we are using to train these models contains information on over 2.4 million transactions, including information on the card and the user. Since most of the transactions are not fraudulent, we have a very imbalanced dataset. Therefore, we first resample the data before training our classification models. Next, we train our four machine learning models and evaluate them, choosing the best model for our goal. In this case, it is important that we minimize the number of false negatives, or cases where the model predicts that there is no credit card fraud when there actually is, because we want to correctly classify all the instances of fraud. We will choose the model that not only has a good accuracy, but also has good sensitivity.

TITLE: Evaluating State-Of-The-Art AI Models for Gin Rummy. 
ABSTRACT: This paper delves into the application of advanced State of the Art reinforcement learning techniques, including Deep Q-Network (DQN), Neural Fictitious Self Play (NFSP), Counterfactual Regret Minimization (CFR), and Deep Monte Carlo (DMC), to address challenges in imperfect information games, with a focus on the two-player card game Gin Rummy. The motivation behind this study is to enhance AI capabilities in video games and potentially real-world imperfect information scenarios, such as military and intelligence operations. Methods like DQN, NFSP, CFR, and DMC are explored for their effectiveness in training models to navigate the complexities of imperfect information games. The implementation involves training models on rule-based and random agents, evaluating their performance through learning curves and tournaments. Specific filtering optimizations had to be applied to begin to see relative success against the rule-based and random agents. Results indicate success with the DMC method, while DQN and NFSP models exhibited suboptimal performance against the rule-based agent. However, training the more successful methods like DMC takes significantly longer than the DQN and NFS methods. The CFR method after multiple optimization attempts, was deemed too computationally expensive to implement on a highly variable and complex game such as Gin Rummy.

TITLE: Disease Detection in Crop Leaves. 
ABSTRACT: In the relentless battle against crop yield losses, early detection of plant diseases stands as a critical weapon. Our research aims to solve this challenge, presenting a two-stage framework that surpasses traditional methods in identifying diseases in real-world plant images. Stage one employs YOLOv8, a state-of-the-art object detector, to pinpoint individual leaves within the captured image. This precise localization paves the way for stage two, where Sequential CNN, a deep learning convolutional neural network (CNN), steps in to perform the intricate task of disease classification. Sequential CNN's exceptional performance in this role, surpassing other contenders like DenseNet121 and MobileNet, lies in its remarkable accuracy from the novel coloration filters it applies at each convolution layer. The three classifiers were trained on the 58k images with 25 different classes using the NewPlantDiseases dataset. Initial experiments conducted on the PlantDoc datasets showcase the framework's potential for classifying non-laboratory produced images. Our initial experiments on the PlantDoc dataset, which captures the complexities of real-world environments, demonstrate that our two-stage framework outperforms YOLOv8 alone by 27.3% in disease detection accuracy. The team proved that the output of the images by YOLOv8’s object detection step can be accurately classified using the trained classifiers. By providing early warnings of disease outbreaks, these tools have the potential to revolutionize agricultural practices, bolster food security, and ultimately, nourish a healthier future.

Summer 2023

TITLE: Autonomous Emergency Braking Pedestrian. 
ABSTRACT: Automotive safety systems have witnessed significant advancements with the advent of computer vision-based object detection algorithms. This paper presents a comprehensive comparative study of three state-of-the-art (SOTA) object detection models, namely You Only Look Once (YOLO), Single Shot Detector (SSD), and RetinaNet, applied to the context of autonomous braking systems. The objective of our project is to identify the most suitable algorithm for both real-time and accurate detection of potential collision objects, enabling efficient automatic emergency braking (AEB) functionality. The study involves extensive experimentation with a diverse dataset of traffic scenarios, including various weather conditions, lighting environment, and road complexities. The performance evaluation metrics include precision, recall, and processing speed which collectively assess the algorithms’ effectiveness for AEB applications. Results indicate that YOLOv5 excels in both accuracy and speed, making it an ideal choice for real-time object detection in autonomous braking scenarios. SSD demonstrates strong performance, striking a balance between speed and accuracy. RetinaNet provides decent accuracy but is not ideal for automotive applications due to the long execution time. Ultimately, this study provides valuable insights for developers and automotive manufacturers seeking to implement autonomous braking systems. Our research and findings will help them choose the most appropriate object detection algorithm based on specific performance requirements and environmental conditions.

TITLE: Using Artificial Intelligence to Predict Student Success at the Secondary Level. 
ABSTRACT: Monitoring academic performance in order to predict which students are at risk of failing and provide the support necessary for course completion is an important element of ensuring educational success. Through the training and application of Support Vector Machine (SVM), Random Forest, and XGBoost, our group aimed to create a high-level ensemble method which accurately predicted the pass or fail status of a student given a set of academic and individual data regarding the student. Our high-level solution used XGBoost to format the data and Random Forest for feature selection, then trained and applied XGBoost, SVM, and Random Forest to the data along with a combined majority voting method that used all three of the other models to predict whether a student will pass or fail. Our best threshold value of 0.05 for Random Forest feature selection narrowed the features down to attendance and G2. Each individual model in our high-level solution had similar performance to each other, with the combined method model performing the poorest and Random Forest achieving the best results of 0.95 accuracy, 0.78 MOC and 0.97 ROC AUC scores.

TITLE: SmartTrash: AI-Enabled Waste Detection. 
ABSTRACT: Waste management has been a growing issue for many years, with each country employing different individualistic solutions. However, many of the solutions applied are not enough to handle the large demand, and as the human population grows, the amount of trash generated will only increase. Therefore, it is imperative that practical and effective solutions be developed to challenge and address waste management. One domain space that has major implications in waste management is deep learning, specifically focusing on detection and classification. Using deep learning the team aimed to produce effective and accurate models by implementing state-of-the-art artificial intelligence architectures, ResNet, VGG, and YOLO. This paper focuses on training, testing, and optimizing each of these architectures and their respective models, in hopes of producing one capable of accurately classifying trash. The team focused on classifying trash accurately, optimizing each model with common best practices. Ultimately, the results from the experiments proved that deep learning can play a crucial role in waste management, with models being capable of classifying trash with over 85% real-world accuracy. Relying on these ResNet, VGG, and YOLO models will allow for other consumer-facing applications, such as cleaning robots, to integrate with the real world, and take action.

TITLE: Harnessing the Power of AI for Diagnosis. 
ABSTRACT: The implementation of artificial intelligence is a growing, and critical tool in the application of medical diagnosis. This paper analyzes how different machine learning applications can be used to assist in heartrelated medical diagnosis. The raw data used to create these models was obtained through a publicly available database known as the MIMIC-III, containing approximately 60,000 admissions of de-identified patient records. The data was pre-processed, and several tables were joined to obtain the data necessary to train the models. The following attributes from the pre-processed dataset were chosen to train the models: “GENDER", "ITEMID_x", "VALUE", "WARNING", "ITEMID_y", "VALUENUM", "FLAG", "Heart Rate", "Systolic", "Diastolic", "ICD9_CODE”. The four models we chose to train were: Support Vector Machine, Decision Tree, K-Nearest Neighbor, and Logistic Regression. Initially the models were trained without considering blood pressure and heart rate, but MCC score and accuracy improved by nearly 10% once those attributes were added to the models. The highest performing model in terms of MCC score is Logistic Regression, with an MCC score of 0.378 and accuracy of 68.3%. To enhance future model performance and MCC scores, further refinements to the input data can be explored. This research demonstrates the potential of AI in assisting medical professionals with accurate heartrelated diagnoses.

TITLE: Swarm Robotics Coordinated Path Planning with Obstacle Avoidance. 
ABSTRACT: This project focuses on swarm robotics and its application to multi-agent path planning for UAVs in unfamiliar environments with unknown static obstacles. Three state-of-the-art (SOTA) methods are evaluated: Multi-Agent Deep Deterministic Policy Gradient (MADDPG), Hybrid Simplified Grey Wolf Optimization with Modified Symbiotic Organism Search (HSGWO-MSOS), and Improved Artificial Potential Field (APF). The A* Search algorithm will be used as a baseline algorithm for comparison with SOTA methods. The project aims to optimize path planning in a 2D simulated environment, considering execution time, complexity, optimality, convergence, completeness, and scalability. Results from 450 runs with 3 swarm sizes and 3 environment scenarios are analyzed for each algorithm to determine the best approach. The project successfully implemented all three methods and developed an effective simulation environment for testing. While certain goals, like measuring convergence effects and expanding to a 3D environment, were not fully achieved, the report provides valuable insights for further improvements. Future work will focus on tuning algorithm parameters, exploring variations of the SOTA methods, and enhancing the realism of the environment, considering inter-agent collisions, moving obstacles, and 3D pathfinding.

TITLE: Supervised and Unsupervised Learning for Network Traffic Classification. 
ABSTRACT: In this paper, we investigate the use of AI for differentiating between Normal and Abnormal computer network traffic in a simulated computer network. Using Supervised and Unsupervised Machine Learning models, we evaluate and compare the performance of each AI model to effectively detect Abnormalities. We describe the network traffic dataset from Coburg University used for training and testing the various learning models and the methods used to discover, clean and normalize the data. We then describe each of the Supervised models (Decision Trees, Support Vector Machines) and Unsupervised models (K-Modes Clustering, Fuzzy K-Clustering, ) used and detail the method of their implementation. We evaluate the performance of each model on the data sets, and compare their ability to effectively detect abnormal network traffic. Finally, we discuss the limitations of our work and possible future work. Our results show AI can be a valuable tool for detecting abnormalities in network traffic. Fuzzy K-Modes (FKM) returned the best prediction results, with scores of 95+%. FKM still requires optimization to achieve this accuracy consistently. Ultimately, we believe our work is the first step in developing a real-world network traffic monitoring tool which can help to improve the security of large scale computer networks.

TITLE: Analyzing State of the Art Methods for Simulated Autonomous Agent Navigation. 
ABSTRACT: This project presents an analysis of three state-of-the-art pathfinding algorithms - Rapidly-exploring Random Trees (RRT), A-Star (A*), and Jump Point Search (JPS) - in the context of autonomous navigation for space rovers. The project aims to compare the performance of these algorithms in a fully observable, two-dimensional environment filled with obstacles, simulating the challenges faced by space rovers on planetary surfaces. The algorithms are evaluated based on path cost, time cost, and the number of iterations required to find a path from a start point to a goal. The performance of each algorithm is tested across eight different maps, each varying in obstacle complexity. Preliminary results indicate that A-Star outperforms RRT and JPS in terms of path cost and time cost, despite theoretical expectations. However, RRT shows remarkable efficiency in terms of iterations. The paper concludes with insights gained from the project and suggestions for future work, including potential improvements to the implementation of JPS and RRT, and the exploration of dynamic path costs and multi-agent scenarios.

Spring 2023

TITLE: Stock Portfolio Optimizer. 
ABSTRACT: Investing in the stock market can be a risk filled endeavor. The sheer quantity of publicly traded companies available to invest in is vast and can be overwhelming. This project presents a few techniques that can be utilized to objectively formulate an investment portfolio that maximizes the risk to returns ratio. An optimized stock portfolio is calculated from historical stock price data using a Genetic Algorithm technique which is further enhanced with a Simulated Annealing Algorithm. Comparisons are made and shown to exceed the performance of the three primary US stock indices (Dow Jones Industrial, S&P 500, and NASDAQ).

TITLE: Touring Popular Tourist Attractions. 
ABSTRACT: Our project represents an approach for touring popular tourist attractions in any given city by utilizing Artificial Intelligence algorithms, namely A-Star Search and K-Means Clustering, to generate an optimal touring route between two high priority tourist attractions. Current state of the art applications have limited efficiency for visiting multiple attractions. GPSmyCity lists popular tourist attractions for a given city and has the ability to suggest an optimal tourist route. However, it has some limitations. Google Maps gives users the ability to add stops along a path, but is reliant on the user picking the order to visit in, and may not necessarily return an optimal path either. Our approach uses Google Maps Places API to return a list of tourist attractions in a chosen city, which then get segmented into clusters using K Means Clustering. Once a user has chosen a desired start and end attraction, they can select other tourist attractions in the city that they may want to explore, and A-Star will find a path between those two attractions, and any other attractions along the way that it deems to be optimal in the cluster network.

TITLE: Revolutionizing MS Diagnosis: The Power of Image Recognition using Convolutional Neural Networking with Transfer Learning Techniques.
ABSTRACT: Multiple Sclerosis (MS) is a chronic neurological disease that affects the central nervous system. Currently, there is no definitive test to diagnose MS, which means the only way to confirm the disease is when the patient has symptoms and there are signs that the condition is affecting the nervous system. It can be very difficult for doctors to diagnose MS and very expensive for the patients to test for this disease. This is where artificial intelligence has stepped in to recognize early onset MS from a patient’s MRI scans. This capability significantly decreases instances of misdiagnosis, reduces the cost of a patient's healthcare bill, and improves a patient’s quality of life. The current state of the art of MS image recognition focuses on the use of deep learning (DL) algorithms, such as convolutional neural networks (CNNs), to detect, segment, and identify lesions in MRI scans of patients' brains. These CNNs are fairly accurate in recognizing signs of MS, and further studies in transfer learning (TL), UNet, and 3-D CNNs have improved the level of accuracy. For our approach, our group chose to implement a CNN structure because of its ability to automatically learn and extract features from large datasets without manually teaching the data what to look for. Our group incorporated transfer learning because our dataset of images with MS is very limited; it requires a more complex, pre-trained model to recognize when a brain scan has MS. Our group used Conv2D layers to construct the CNN model and utilized grid search to tune the hyperparameters, which involves trying different combinations of hyperparameters and evaluating their performance on the test set. Using the Xception transfer learning model, our team was able to successfully detect MS lesions from MRI scans with85.7% validation accuracy. Our model performed very well when comparing our accuracy rating to those of the SOTA methods we analyzed.

TITLE: The Fruit-ture: Using Image Recognition to Detect Produce Freshness. 
ABSTRACT: Reducing food waste has become a major focus by producers and consumers to decrease their carbon footprint and to fully make use of their resources. Forty percent of this waste happens at grocery stores, restaurants, and homes, so being able to track food freshness in each area would be key in tackling this problem. One solution would be to use a combination of photo capture and image-based artificial intelligence to monitor freshness. In this study, image-based techniques such as convolutional neural networks, AlexNets, and HRFormers will be discussed and compared in their ability to detect fruit freshness on apples, bananas, and oranges. AlexNet trained with PyTorch appears to outperform these models in terms of computational cost, having the lowest training time, while still maintaining comparable accuracies.

TITLE: Fault Detection in Robot Swarms. 
ABSTRACT: This project presents a novel approach to fault detection in robot swarms inspired by natural flocking behaviors. The current state-of-the-art methods, Collective Decision through Majority-based Cross-Inhibition (CDMCI) and Cross Regulation Model (CRM), have some limitations which our approach aims to overcome. Our novel approach applies the boids algorithm to simulate a swarm's movement through an environment and uses a deep learning neural network to identify normal and abnormal agent states. Experimental results indicate the effectiveness of our AI-based approach in identifying various types of abnormal agent behavior in boid simulations, with potential for further refinement and application in other domains.

TITLE: An Investigation into the Use of AlphaZero in Dots and Boxes. 
ABSTRACT: This project focuses on the testing of the AlphaZero algorithm against both Minimax (with AlphaBeta pruning) and Monte Carlo Tree Search in the game of Dots and Boxes. In this paper, we outline our approach for implementing a working game system for Dots and Boxes as well as a way for all algorithms to play against each other within the game. In addition, we outline the metrics we utilize to test the effectiveness of all algorithms, such as win rate, margin of victory, and time to compute each move. In addition, we detail how we tested each algorithm on several different gameplay scenarios to see if they chose the most optimal strategy. Our tests were on 3x3 and 5x5 board sizes. Our results show that AlphaZero was able to outperform the other two algorithms on the smaller size gameboard with minimal training; however, lack of training became apparent when moving to the 5x5 gameboard and AlphaZero performed the worst of the three. AlphaZero was consistently the slowest algorithm.

TITLE: Corrosion Detection and Mitigation with Computer Vision. 
ABSTRACT: Corrosion in its many forms has the potential for serious, pervasive, lingering, and irreparable damage to equipment, tools, vehicles, and structural components, and it has posed these problems since humanity very first began to make use of metals. In today’s modern and rapidly evolving world, where metallic components are frequently used for critical design elements, such as turbine blades, load bearing elements, functional components of communication or power distribution infrastructure, or the hulls of various commercial or military ships, it is of the utmost importance that corrosion and associated structural damage must be detected and prevented proactively. Currently, maintenance professionals and programs make use of a great variety of tools and methods to detect, identify, prevent, and address corrosion and corrosion-related issues, but as the size, complexity, and importance of these vulnerable components increases, so too does the potential damage that may occur if a corrosion-based issue were to escape notice. In this project, the team hopes and plans to create and leverage a novel AI agent utilizing Computer Vision technologies to detect rust or similar metallic corrosions on various types of metallic surfaces in an attempt to address and better understand this problem.

Fall 2022

TITLE: Sports Betting: Which Will Win?
ABSTRACT: Professional sports are a popular pastime around the world. As a result, many companies offer services in which individuals can place bets on the outcome of certain components of a sporting event. One such sport in which this service is offered is Ice Hockey. One such criterion a spectator can bet on is the total number of goals scored. In this paper, we attempt to build a model which can accurately forecast the total number of goals scored in a National Hockey League game using publicly available data. We do this by testing three types of classifiers Random Forest Classifier, Bagging Classifier, and Logistic Regression Classifier–on six sets of data, each of which with some variation in the amount of information the data provides. We test each of the 18 ClassifierData combinations using the Root Mean Square Error to find the most accurate classifier/data combination. Consequently, we also test which types of classifiers are most susceptible to a change in data. We find the most accurate combination is the Random Forest Generator with the most abundant data set. We also find that the Random Forest Generator classifier was the most susceptible to additional information, making it an ideal candidate for further improvements on the model.

TITLE: Predicting the Producer Price Index of Insulin. 
ABSTRACT: For our project, we wanted to be able to predict the future price of insulin based on the prices that have been set currently and in the past. Being able to accurately predict the Producer Price Index (PPI) of insulin to a certain range would help those in need be able to find the necessary medicine needed to live at an affordable price. To predict the PPI insulin, our model would use the Fisher Price Index on a set of data. The predicted PPI of insulin would be based on the data that was given along with previous data already given to the model to more accurately pick an accurate price. To measure the success of our model, we would compare our models' predictions of older data to how the data turned out and based on that success, would give us a good understanding of how accurate it could be for data now to predict future prices. The current results include a polynomial regression produced using a machine learning model, as well as data points to predict future PPI.

TITLE: Using Reinforcement Learning in Robotic Simulations. 
ABSTRACT: The overall goal of this project is to design and implement a robot that is capable of navigating a simulated environment and pushing a cylinder obstacle to a specific goal. To achieve this, we have decided to use a reinforcement learning approach, specifically Deep Q-learning. Setting up the environment and getting the reinforcement learning model working have been significant milestones in this project. In order to properly train the robot, we have utilized Gazebo and ROS to create a virtual environment for a simulated robot to operate in. We then focused on implementing the reinforcement learning algorithm. This involved setting up the reward function, and configuring the training process. Overall, this project has required a combination of technical skills in robotics, machine learning, and computer simulation.

TITLE: AI Resume Checker. 
ABSTRACT: The overall purpose of our project is to create and develop an AI-powered tool for analyzing, summarizing, and comparing resumes and job descriptions. The AI accurately parses and identifies keywords in the resume and job descriptions, making it easier for users to cater their resumes to apply to specific jobs. To achieve this, our team is utilizing natural language processing and machine learning techniques to accurately identify and extract key information from text documents(resumes). We will also be incorporating user feedback and continuous testing to improve the accuracy and effectiveness of our AI. So far, we have successfully implemented the core functionality of our AI parser and comparison tool and are looking to test it with a group of users. We have also tried the AI agent for our own resumes and have had very positive feedback. We are currently working on refining the user interface and user experience. In the future, we plan to continue to develop and refine our AI parser and keyword comparison tool to make it a truly usable, free, and practical tool for individuals and users to easily understand and have more catered and streamlined resumes for jobs.

TITLE: Developing a Pathfinding Application to Navigate the Worcester Polytechnic Institute (WPI) Campus. 
ABSTRACT: The goal of this project was to develop a pathfinding application for navigating the Worcester Polytechnic Institute (WPI) campus. Our motivation was to create a resource that can help new students transition to college life and reduce stress that is associated with navigating campus and being late for class. We utilized four search algorithms, those being Best-First Search, A* Search, Hill Climbing, and Simulated Annealing, to compute the most optimal routes around campus based on a student’s schedule. Each of these algorithms has their own strengths and weaknesses, and may be more or less optimal than the others depending on the situation. The application chooses the most optimal route each time it makes a recommendation based on minimizing the time it takes to get to the goal state. The application takes a student’s schedule as input and shows them the recommended route to all of their destinations highlighted on a map. The team used Kivy to develop the user interface of the application and present the recommended routes over a map of the WPI campus. After evaluating the apps performance with a series of test cases we found that the application was successfully able to recommend realistic routes for a variety of student schedules. It also effectively handled errors such as incompatible input file types.

TITLE: Analyzing an Expanded Number of Emotions in Tweets. 
ABSTRACT: Artificial intelligence (AI) has the potential to revolutionize the way we understand and analyze emotions in social media texts such as tweets. By analyzing the language and sentiment of tweets, we hope to accurately identify the emotional state of the tweet's author. To address this project, we are using a combination of natural language processing techniques and machine learning algorithms. We have collected a large dataset of tweets with some labeled with their corresponding emotions. Our model aims to analyze the language and context of tweets to identify patterns and features associated with different emotions. The use of AI for emotion detection in tweets can have a wide range of applications, including improving customer service, identifying public sentiment, and understanding the emotional impact of events and topics. However, it is important to carefully consider the ethical and legal implications of using AI for emotion detection in social media, as well as the potential for biases in the training data.

TITLE: Tumor Detection from Magnetic Resonance Imaging. 
ABSTRACT: The use of artificial intelligence (AI) in medical scans and imaging has the potential to revolutionize the way that doctors diagnose and treat various diseases, including brain tumors. In this report, we describe our AI application that analyzes a set of brain MRI scans and uses several learning models to predict whether or not the images contain a brain tumor. The ability to detect a brain tumor early, before it starts causing symptoms in the patient, is invaluable to treating the condition and saving the patient’s life. That is exactly what we hope to achieve with this application: to find the best learning model that can diagnose brain tumors from MRI scans, and use it to predict the presence of brain tumors from future MRI scans. This will potentially save patients’ lives by allowing medical professionals to deliver early treatment.

TITLE: Evaluating Natural Language Processing Methods to Detect Misinformation. 
ABSTRACT: Communication and information consumption have changed as a result of the World Wide Web. Online social networks are currently one of the most popular and efficient tools for information sharing. In a very short period of time, information can spread from the original sources to a large number of users. Although social media platforms are efficient at information sharing, this can come at a cost. Due to the it’s effective nature of the spread of information, social media platforms not only allow for the effective dissemination of true news, but also of incomplete or even completely false information. (Amoruso, M., Anello, D., Auletta, V., Cerulli, R., Ferraioli, D., & Raiconi, A. 2020). The goal of our project is to create an application that addresses the problem of misinformation online. We will focus on a specific approach in an attempt to limit the spread of false information. Our approach is to train our natural language processing model with the LIAR dataset, and to numerically quantify the truthfulness of statements from 0 to 1 as accurately as possible using regression, with 1 being most true.

TITLE: Using Recurrent Neural Networks to Predict the Outcomes of NFL Games. 
ABSTRACT: Betting on Football is a significant task with numerous studies dedicated to it. Our intention is to expand the field of sports betting in general and football gabling specifically with a novel deep learning method for calculating the outcome of games. By using existing game data to train a recurrent neural network, we intend to create a more effective and efficient algorithm for predicting games.

TITLE: Obtaining Encryption Keys from Encrypted and Unencrypted Data Utilizing Supervised Machine Learning - Decision Trees, Support Vector Machines, and Gaussian Naïve Bayes Classifiers.
ABSTRACT: As elements of our life increasingly intertwine with our internet usage, cybersecurity has and will continue to rise in importance. We use cryptography to help keep the keys to our life secure, being our financial, intellectual, and personal assets. Unfortunately, cryptography is a constant battle against ever-evolving computer technology. Our team demonstrates how modern artificial intelligence and machine learning can be used to crack encrypted passwords of previous technology, highlighting the importance of the acceleration in the development of encryption standards. In addition to the encryption-cracking threats, there is the social issue of people choosing insecure, easily cracked passwords to protect their lives. Although service providers are now requiring users to set more secure passwords, this is not a set standard and because many people use a similar, if not the same password for most of their online accounts, their online security can be compromised if a password associated with their email account is discovered. Our project has managed to crack basic encrypted passwords with a success rate of over 90%, illustrating the dangerous combination of modern artificial intelligence technology and a lack of ubiquitous understanding of password security considerations.

TITLE: Using artificial intelligence to perform group formation based on Belbin’s team roles. 
ABSTRACT: Humans are more productive in teams, especially when individuals can specialize. This creates a challenge for many leaders in industries and classrooms; that of creating the most optimal teams from a group of people such that each team can perform as well as possible. This project explores the idea of using artificial intelligence to create teams from a given group of people such that they are the most optimal teams. After exploring existing solutions, the algorithm chosen was one that used a heuristic based on two theories, Belbin’s team roles and Smith’s theory of specialization to create teams. The final application is able to take survey data regarding people’s primary Belbin team role as well as proficiency in three distinct skills and optimize them into teams of 26.

TITLE: Training an Artificial Intelligence Agent To Master the Retro Arcade Video Game Pac-man Using A Linear Q Neural Net Model Against Several Artificial Intelligent Ghosts.
ABSTRACT: After discovering an artificial intelligence agent designed to play the retro game Snake to get the highest score possible, we wanted to attempt to design a similar agent to play a slightly more complex game, PacMan. Pac-Man is a retro game in which the player collects pellets, adding to their score while avoiding four ghosts that attempt to catch the player. For our application, we simplified the ghost artificial intelligence by making their pathfinding the same, whereas in the original game, each ghost has slightly different behaviors. Using an implementation of a linear q neural net model, we attempted to develop an agent that would efficiently play PacMan, to get the highest score while avoiding four ghost obstacles. We used the PyGame library to mimic the original Pac-Man game board and coded a simple artificial intelligence to emulate the four ghosts to serve as an obstacle for the agent to learn to avoid. Throughout the program’s runtime, the agent loops through multiple Pac-Man games, until the program is manually terminated. The agent’s progress is tracked with a graph displaying the score received and the game number and is updated after each game ends. With this application, we hope it will be useful in discovering how an agent could be designed to play different simple video games, and potentially more complex games, by exploring the states an agent has to keep track of.

TITLE: Exploring Monte Carlo Methods for Battleship AI. 
ABSTRACT: In this paper, we explore an approach for enabling AI agents to effectively play the game of Battleship. Our approach is based on the use of Monte Carlo simulations, which allow the agent to evaluate the potential outcomes of different moves and make decisions accordingly. Through extensive experimentation, we show that our AI agent is able to consistently outperform random move based agents as well as simple hunting strategies, achieving a high level of success in the game. To implement our approach, we first develop a simulation model that accurately represents the game of Battleship. This model is used by the AI agent to simulate the potential outcomes of different moves and select the one with the highest expected value. Overall, our results demonstrate the effectiveness of using Monte Carlo simulations for enabling AI agents to play the game of Battleship.

TITLE: Optimizing Package Delivery using Collaborative Agents. 
ABSTRACT: With the increasing demand for online shopping retailers and delivery services, we wanted to focus on agents that could optimize the delivery service for customers and companies. Our ultimate goal is to develop collaborative agents that can effectively find the shortest path to its destination while actively communicating with other agents to facilitate any other deliveries in the system. These communications include reroute broadcasting, package handoffs, and collision detection. By utilizing localized scanning algorithms alongside scatter search methods, each individual agent can scan its surrounding area for roadblocks in its path. And after identifying a roadblock, this agent can broadcast a message to all other agents which allows them to readjust their current paths if necessary. The localized scanning also allows for agents to identify when other agents are nearby and resolve any conflicts in their pathing. Alongside localized scanning systems, nearby agents can also communicate deliveries they currently have queued which allows for other agents to identify if they can take a package from that agent to facilitate their delivery process. By implementing this process of package handoffs, we improved the efficiency of a group of delivery agents as they were able to identify when to hand off packages to other agents who were servicing a destination in the vicinity of their own package.

Summer 2022

TITLE: Evaluating the Effectiveness of the AlphaZero Methodology in an Alternative Setting. 
ABSTRACT: With AlphaZero’s groundbreaking performance in chess, we wanted to evaluate its effectiveness in other complex settings, leading to this case study on AlphaZero Ultimate Tic Tac Toe (UTTT). Building off of prior work done on an AlphaZero model for UTTT, we expanded the complexity of the game through increasing the board size and number of players to evaluate how the model’s success changes with this increased complexity. To measure the success of our model, we recorded data on the time taken per move and per game, the average number of moves, and the win rate. Given the constraints of this project, the model was unable to consistently perform better than standard algorithms such as minimax and Monte Carlo Tree Search, but it was able to consistently perform faster.

TITLE: Detecting American Sign Language Using Deep Learning.
ABSTRACT: This project puts forth an application demonstrating the potential for the development of convenient ASL translation through the usage of deep learning. The framework takes video camera footage as input and utilizes Google’s MediaPipe to produce “landmarks” based upon the detected hand shape. We train a multi-layer perceptron on our prepared and labeled landmark data. We evaluate our results using both a train/test split for the model as well as in-person testing of the application to ensure we receive similar practical results. We aim to expand upon past efforts in this field by testing the effects of increasing the learned vocabulary as well as demonstrating the efficacy of MediaPipe as a method of input.

TITLE: Utilizing Genetic Algorithms to Develop an Efficient Traffic Light Autonomous Agent. 
ABSTRACT: We propose a novel agent for controlling a collection of traffic lights across a complex city grid of intersecting streets. This agent will be fed approximate traffic counts of vehicles at each light and their directions as input. From this the agent must coordinate light timings. We shall be utilizing an evolutionary algorithm to train an agent against a fitness function that minimizes the delayed time of vehicles moving to their destination. An efficient agent should maintain a low total waiting time for vehicles trying to move through the city.

TITLE: Abracadabra: Voice Commands in Video Games. 
ABSTRACT: The goal of this project was to implement a speech recognition system into a video game that would allow users to control said game using their words. The idea of “magic spells” was chosen as that was the premise that made the most sense in terms of what could be controlled with one’s voice. We integrated a pre-existing Python library into the C# of Unity, which allowed us to experiment with various popular voice recognition systems, including Google Cloud, Wit, Azure and Houndify. Ultimately, we found that Google technology was the best for our purposes: although it didn’t have the highest accuracy, it did boast the highest speed. When the user's voice goes through the microphone, Pyaudio will accept the voice and translate voice to internal audio representation. Then the google speech recognition API is called to translate audio to text. Once text is generated, we use simple heuristic to extract keywords out of the text and map it to game control commands. Our major results are the speech API can recognize pure keyword voice and execute some simple commands, game engine can identify various colors of the rainbow when users speak English, and implement a simple custom color function.

TITLE: Text to Therapy. 
ABSTRACT: Mental health chatbots could be the solution to providing much needed psychological support in an accessible, private, and destigmatized way. However, with the resources available today, constructing a superior mental health chatbot utilizing advanced and non-proprietary natural language processing is not yet feasible. A mental health chatbot with advanced natural language processors that are supportive and kind to the user while sounding natural in their speech patterns is very sparse if not non-existence when compared to the chatbots that are currently released. Advanced NLPs produce a high rate of toxic languages to which there have been no improvements in the years since they have been released. Additionally, HIPAA regulations also cause data access issues as these models have no verified data to work with. In this paper we provide an overview of the current mental health chatbots including Talkspace, Wysa, Woebot, and Joyable, as well as the issues with GPT-3, one of the leading NLP in the tech world and why it cannot be used in a delicate environment such as the mental health field.

TITLE: Developing an Intelligent Tutoring System for Organic Chemistry. 
ABSTRACT: Learners benefit from individually tailored learning experiences. Intelligent tutoring systems are technology-based learning systems that can adapt the learning experience so as to better serve an individual user. DiscoverOChem is a free internet-based platform for learning undergraduate-level organic chemistry. The current work aims to develop intelligent tutoring aspects that can be implemented into this platform. Data from previous years of students is used to analyze how well individual students have performed on various pages of the platform. Correlations between pairs of pages, as well as correlations between pages and exam outcomes are analyzed. Predictive models, which use a user’s results on previous pages to predict that user’s likely performance on upcoming pages, are developed. The most successful of these models, which involves a boosting approach and decision tree methods, is implemented into an offline development version of DiscoverOChem. This implementation functions as a recommender system to help users identify pages that are likely to challenge them and to provide useful review page recommendations that help the user prepare for the upcoming page.

TITLE: Improving Operator Workflow in Enterprise Resource Planning (ERP) Software using Natural Language. 
ABSTRACT: This paper presents a solution for interactions between manufacturing workers and a main kiosk machine via chatbot. In this particular chatbot, the goal is to achieve quick and human like interactions between user and machine. Two model frameworks, a Base Chatbot NLP Model and a Database Query NLP model, are explored and used in tandem to achieve the desired interactions. The Base Chatbot will handle basic questions and answers and the Database Query NLP model will handle ERP queries and answer retrieval. The methodology will include training the base chatbot model through ”intents”. These intents will provide a base foundation for generic communication between the user and the bot. The Database Query NLP model consists of many pretrained transformer models that allow for query understanding and answer generation, all related to the ERP data.

TITLE: Weight Agnostic Neural Network Exemplified Through Assault. 
ABSTRACT: A Weight Agnostic Neural Networks (WANN) was used on a computer game called Assault. WANN was chosen for this implementation as it could be faster at learning than a traditional neural network. It was developed in order to emulate learning of precocial behaviors. The model used the game’s memory as an input and showed marginal performance. We then chose to modify the weight agnostic neural network model by using a VAE of the screen as the input to demonstrate improved results.

Spring 2022

TITLE: Feature-Driven Next View Planning for Robotic Metal Scrap Cutting. 
ABSTRACT: Metal recycling in scrapyards, where workers cut decommissioned structures using gas torches, is labor-intensive, difficult, and dangerous. As global metal scrap recycling demands are rising, robotics and automation technologies could play a significant role to address this demand. However, the unstructured nature of the scrap cutting problem—due to highly variable object shapes and environments—poses significant challenges to integrate robotic solutions. We develop a collaborative workflow for robotic metal cutting that combines worker expertise with robot autonomy. In this workflow, the skilled worker studies the scene, determines an appropriate cutting reference, and marks it on the object with spray paint. The robot, then, autonomously explores the surface of the object for identifying and reconstructing the drawn reference, converts it to a cutting trajectory, and finally executes the cut. This project focuses on the surface exploration and cutting reference reconstruction tasks, which require appropriate next view planning (NVP) algorithms. We design our feature-driven viewpoint planner and compare it against two state-of-the-art methods. Our NVP algorithm enables the robot to explore and extract desired features from the scene, i.e., the drawn reference, without requiring any a priori object model. Contrasting with global or feature-agnostic NVP algorithms, our approach guides the robot via desired local features to increase the efficiency of the exploration. We evaluate our NVP algorithm against six categories of objects both in simulation and in physical experiments.

TITLE: Ensemble Convolutional Neural Networks for Robotic Planar Grasping. 
ABSTRACT: This project presents an ensemble learning framework and methodology for robotic grasp synthesis and grasp quality estimation. In this framework, multiple existing robotic grasping algorithms provide their outputs for an image input. In this methodology, these individual algorithms are treated as “experts” voting on grasp “opinions”. We design a convolutional neural network for an ensemble gating network using a Mixture-of-Experts model. This integrates the outputs of each individual expert and determines a final grasp to be executed by the robot. We evaluate our methodology in simulation and in real-robot experiments to show that our ensemble network outperforms the success rate of any of its individual experts. We use the networks GQ-CNN 4.0 which is trained on the synthetic Dex-Net dataset and we use two instances of GG-CNN, one trained on RGB data and one trained on depth data. We evaluate our ensemble network on the Cornell Grasping Dataset. We use the Franka Emika Panda arm for a robotic arm in a ROS/Gazebo environment as well in a real-robot experiment. Our RGB-D camera is the Intel RealSense D435.

TITLE: Applications of Auditory Design in Artificial Intelligence. 
ABSTRACT: Noise canceling has become a staple feature in many high-end headphones on the market today. They provide the benefit of canceling the surrounding noises to provide the user with a quiet background to then play music over. The problem arises when the headphones cancel out sounds that alert the user of an issue. The technology in noise canceling headphones can be improved on by allowing the bypassing of certain sounds to alert the listener to unique and important sounds that would otherwise be negated by the noise canceling. By combining Rattlesnake and Recurrent Neural Network (RNN) we have developed a methodology that allows for unique sounds to remain unfiltered while still continuing to cancel out unwanted background noise. Using RNN we can obtain the predicted background noise of a given environment. Then combining the predicted background noise with Rattlesnake, we can then invert the background noise and combine it with the original. Our findings after testing showed some success, there is still room for improvement.

TITLE: Improving Cancer Image Detection through AI/ML Strategies to Reduce Translation Invariant. 
ABSTRACT: Artificial intelligence models have achieved great success in cancer imaging. These models are often deep convolutional neural networks (DCNNs), and are most effectively used to supplement professional analyses. It is found that these networks have their drawbacks, as they are prone to overfitting and require massive amounts of labeled medical data to train. In this paper, we proposed a novel method of replacing the fully connected layers of DCNNs with pooling layers. This was performed using average pooling, global average pooling, max pooling, and max average pooling. Compared to more typical DCNN models, our proposed method can prevent overfitting tendencies without expensive hyperparameter tuning. Our model can also improve performance over more typical DCNNs while using smaller batch sizes. Experimental results on global average pooling demonstrate the effectiveness of the proposed method, outperforming the no-pooling model by a margin of nearly 5% for both recall and accuracy.

TITLE: Extensions and Updates to the Wave-U-Net Deep Learning Neural Network for Audio Source Separation. 
ABSTRACT: This project stood to investigate the practical feasibility of applying artificial intelligence topics to audio source separation (isolating individual instruments in a song, for example). Specifically, we were investigating current implementations, what their limitations are, where they can be improved, and which of the current solutions performs the best. We worked to upgrade the baseline architectures to modern machine learning platforms for feasible scaling in the future. We started with the Wave-U-Net architecture as a baseline and implemented a handful of extensions and alternative approaches to compare their performance. These approaches vary widely in their implementation and success due to differences in hardware and time needs. This work is relevant as more and more applications are beginning to exist that require accurate and timely separation of single channel audio. Through this project, we found that Wave-U-Net is an effective architecture for audio source separation, especially with a control unit extension, and that, while it would be beneficial to upgrade the framework to Tensor flow 2, this proved to be a larger undertaking than the team could accomplish in the scope of this course.

TITLE: Optimized Teammate Selection with a Focus on Member Compatibility to Domain Roles. 
ABSTRACT: The goal of this project is to develop a Machine Learning tool for predicting the performance of a team of individuals solely based on the strengths and weaknesses of its individual members in past experiences before the team’s formation. There exist models in the field for predicting team performance based on that team’s past performance, but we feel that having a model that helps to optimize team formation can assist and improve existing processes further. We tested our theory by developing a tool to assist with the drafting process in FIRST Robotics competitions, which involves the top 8 competitors in a given tournament selecting their teammates from the other competitors based on their performance in a series of qualification matches. During the project, we developed a model for evaluating individual and team strengths and weaknesses, developed a tool for optimizing team formation based on the model, built an algorithm that can predict the outcome of a game with 80% validation accuracy, and used that algorithm to predict the performance of an optimized team against historic and user-generated data.

