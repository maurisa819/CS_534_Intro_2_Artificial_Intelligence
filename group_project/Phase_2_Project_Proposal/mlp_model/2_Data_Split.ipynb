{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff7f8699",
   "metadata": {},
   "source": [
    "Objective:\n",
    "Split data into 80/20 train/test, then split the 80 into 80/20 train/val.\n",
    "Should end up with approx (minimum, could be more depending on Code_Inspect results): \n",
    "- 9,659 test\n",
    "- 7,727 val\n",
    "- 30,908 train\n",
    "This should be sufficient for our models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6fb8528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6691d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nazario_aid = [0, 1]   # Manual. There was a mistake in 1_Code_Inspect, so a random sample was never taken\n",
    "Ling_aid = [1584, 1746, 772, 1729, 387, 407, 2441, 1992, 2448, 2755]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d12eb2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7-Column Sets\n",
    "Nigerian_Fraud_df = pd.read_csv(\"data/Nigerian_Fraud.csv\")\n",
    "Nazario_df = pd.read_csv(\"data/Nazario.csv\")\n",
    "SpamAssasin_df = pd.read_csv(\"data/SpamAssasin.csv\")\n",
    "CEAS_08_df = pd.read_csv(\"data/CEAS_08.csv\")\n",
    "\n",
    "\n",
    "# 3-Column Sets\n",
    "Ling_df = pd.read_csv(\"data/Ling.csv\")\n",
    "Enron_df = pd.read_csv(\"data/Enron.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a46b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzed rows\n",
    "Ling_analyzed = Ling_df.loc[Ling_aid]\n",
    "Nazario_analyzed = Nazario_df.loc[Nazario_aid]\n",
    "\n",
    "# Remaining rows\n",
    "Ling_remaining = Ling_df.drop(Ling_aid)\n",
    "Nazario_remaining = Nazario_df.drop(Nazario_aid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ed30657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Train/Test for 7-Colum no analysis\n",
    "Nigerian_Fraud_train1, Nigerian_Fraud_test = train_test_split(Nigerian_Fraud_df, test_size=0.2, random_state=42)\n",
    "SpamAssasin_train1, SpamAssasin_test = train_test_split(SpamAssasin_df, test_size=0.2, random_state=42)\n",
    "CEAS_08_train1, CEAS_08_test = train_test_split(CEAS_08_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# First Train/Test for 7-Column with analysis\n",
    "Nazario_train1, Nazario_test = train_test_split(Nazario_remaining, test_size=0.2, random_state=42)\n",
    "\n",
    "# First Train/Test for 3-Colum no analysis\n",
    "Enron_train1, Enron_test = train_test_split(Enron_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# First Train/Test for 3-Column with analysis\n",
    "Ling_train1, Ling_test = train_test_split(Ling_remaining, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1075599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Train/Test for 7-Colum no analysis\n",
    "Nigerian_Fraud_train, Nigerian_Fraud_val = train_test_split(Nigerian_Fraud_train1, test_size=0.2, random_state=42)\n",
    "SpamAssasin_train, SpamAssasin_val = train_test_split(SpamAssasin_train1, test_size=0.2, random_state=42)\n",
    "CEAS_08_train, CEAS_08_val = train_test_split(CEAS_08_train1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Second Train/Test for 7-Column with analysis\n",
    "Nazario_train2, Nazario_val = train_test_split(Nazario_train1, test_size=0.2, random_state=42)\n",
    "Nazario_train = pd.concat([Nazario_train2, Nazario_analyzed])\n",
    "\n",
    "# Second Train/Test for 3-Colum no analysis\n",
    "Enron_train, Enron_val = train_test_split(Enron_train1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Second Train/Test for 3-Column with analysis\n",
    "Ling_train2, Ling_val = train_test_split(Ling_train1, test_size=0.2, random_state=42)\n",
    "Ling_train = pd.concat([Ling_train2, Ling_analyzed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73f14d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify no duplicate indices\n",
    "try:\n",
    "    Ling_train.index.has_duplicates\n",
    "except:\n",
    "    raise IndexError(\"Duplicate indices found in Ling_train. Verify the code flow.\")\n",
    "\n",
    "try:\n",
    "    Nazario_train.index.has_duplicates\n",
    "except:\n",
    "    raise IndexError(\"Duplicate indices found in Nazario_train. Verify the code flow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0106893d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Nigerian_Fraud_train to Split_Data/Uncleaned/Nigerian_Fraud_train.csv\n",
      "Saved Nigerian_Fraud_val to Split_Data/Uncleaned/Nigerian_Fraud_val.csv\n",
      "Saved Nigerian_Fraud_test to Split_Data/Uncleaned/Nigerian_Fraud_test.csv\n",
      "Saved Nazario_train to Split_Data/Uncleaned/Nazario_train.csv\n",
      "Saved Nazario_val to Split_Data/Uncleaned/Nazario_val.csv\n",
      "Saved Nazario_test to Split_Data/Uncleaned/Nazario_test.csv\n",
      "Saved SpamAssasin_train to Split_Data/Uncleaned/SpamAssasin_train.csv\n",
      "Saved SpamAssasin_val to Split_Data/Uncleaned/SpamAssasin_val.csv\n",
      "Saved SpamAssasin_test to Split_Data/Uncleaned/SpamAssasin_test.csv\n",
      "Saved CEAS_08_train to Split_Data/Uncleaned/CEAS_08_train.csv\n",
      "Saved CEAS_08_val to Split_Data/Uncleaned/CEAS_08_val.csv\n",
      "Saved CEAS_08_test to Split_Data/Uncleaned/CEAS_08_test.csv\n"
     ]
    }
   ],
   "source": [
    "# Make output directory if it doesn't exist\n",
    "output_dir = Path(\"Split_Data/Uncleaned\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Set output path to previously make output directory, save files\n",
    "to_save = ['Nigerian_Fraud', 'Nazario', 'SpamAssasin', 'CEAS_08', 'Enron', 'Ling']\n",
    "save_levels = ['_train', '_val', '_test']\n",
    "\n",
    "for dataset in to_save:\n",
    "    for level in save_levels:\n",
    "        var_name = f\"{dataset}{level}\"\n",
    "        df = globals().get(var_name)\n",
    "\n",
    "        if df is not None:\n",
    "            output_path = output_dir / f\"{var_name}.csv\"\n",
    "            df.to_csv(output_path, index=False)\n",
    "            print(f\"Saved {var_name} to {output_path}\")\n",
    "        else:\n",
    "            print(f\"Variable '{var_name}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0000b4-d828-4959-9e02-7ab5f63f06eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
